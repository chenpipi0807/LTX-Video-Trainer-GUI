#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
LTX-Video-Trainer ä¸“ä¸šç‰ˆUIç•Œé¢
æä¾›è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—è¾“å‡ºå’Œè¿›åº¦åé¦ˆ
æ”¯æŒé…ç½®æ–‡ä»¶ã€æ•°æ®é¢„å¤„ç†å’ŒComfyUIæ ¼å¼è½¬æ¢
"""

import os
import sys
import logging
import json
# ä½¿ç”¨jsonä»£æ›¿yaml
# import yaml
import threading
import subprocess
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from safetensors.numpy import save_file

# è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
os.environ["PYTHONIOENCODING"] = "utf8"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"

# è·å–é¡¹ç›®æ ¹ç›®å½•å’Œå…¶ä»–é‡è¦ç›®å½•
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
SCRIPTS_DIR = os.path.join(PROJECT_DIR, "scripts")
CONFIG_DIR = os.path.join(PROJECT_DIR, "config")
DATA_DIR = os.path.join(PROJECT_DIR, "train_date")

sys.path.append(PROJECT_DIR)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger('LTX-Pro-Trainer')

# åˆ†è¾¨ç‡é€‰é¡¹
RESOLUTIONS = [
    "512x512x25", "576x576x25", "640x640x25", "704x704x25", "768x768x25",
    "512x512x49", "576x576x49", "640x640x49", "704x704x49", "768x768x49",
    "576x1024x41", "1024x576x41"
]

# å¯èƒ½çš„LTXæ¨¡å‹è·¯å¾„
POSSIBLE_MODEL_PATHS = [
    # é¡¹ç›®å†…éƒ¨è·¯å¾„
    os.path.join(PROJECT_DIR, "models"),
    # ComfyUIè·¯å¾„
    r"C:\NEWCOMFYUI\ComfyUI_windows_portable\ComfyUI\models\checkpoints",
]

# è¯»å–é…ç½®æ–‡ä»¶
def load_config(config_path):
    """åŠ è½½JSONé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

# ä¿å­˜é…ç½®æ–‡ä»¶
def save_config(config, config_path):
    """ä¿å­˜é…ç½®åˆ°JSONæ–‡ä»¶"""
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2)
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

# è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶
def get_config_files():
    """è¯»å–å¯ç”¨çš„é…ç½®æ–‡ä»¶"""
    config_files = {}
    try:
        if os.path.exists(CONFIG_DIR):
            for file in os.listdir(CONFIG_DIR):
                if file.endswith(".json"):
                    name = file.replace(".json", "")
                    config_files[name] = os.path.join(CONFIG_DIR, file)
        return config_files
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        return {}

def check_dataset_location(basename):
    """æ£€æŸ¥æ•°æ®é›†ä½ç½®å¹¶è¿”å›æœ‰æ•ˆçš„è·¯å¾„"""
    # é¦–å…ˆæ£€æŸ¥train_dateç›®å½•
    train_date_path = os.path.join(PROJECT_DIR, "train_date", basename)
    if os.path.exists(train_date_path) and os.listdir(train_date_path):
        logger.info(f"æ‰¾åˆ°train_dateç›®å½•ä¸‹çš„æ•°æ®é›†: {train_date_path}")
        return train_date_path
        
    # ç„¶åæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„_rawç›®å½•
    raw_path = os.path.join(PROJECT_DIR, f"{basename}_raw")
    if os.path.exists(raw_path) and os.listdir(raw_path):
        logger.info(f"æ‰¾åˆ°åŸå§‹ç»“æ„æ•°æ®é›†: {raw_path}")
        return raw_path
        
    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›None
    return None

def run_command(command, status=None, verbose=True):
    """è¿è¡Œå‘½ä»¤å¹¶å®æ—¶æ›´æ–°çŠ¶æ€"""
    process = subprocess.Popen(
        command,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        universal_newlines=True
    )
    
    output = []
    for line in process.stdout:
        if verbose:
            print(line, end='')
        output.append(line.strip())
        if status and hasattr(status, 'update') and len(output) % 5 == 0:
            status.update(value="\n".join(output[-25:]))
    
    process.wait()
    return process.returncode, "\n".join(output)

def find_ltx_model(model_name_pattern="ltxv-13b"):
    """æŸ¥æ‰¾LTXæ¨¡å‹æ–‡ä»¶
    
    Args:
        model_name_pattern: æ¨¡å‹åç§°æ¨¡å¼ï¼Œå¦‚ltxv-13b
        
    Returns:
        æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„æˆ–None
    """
    for path in POSSIBLE_MODEL_PATHS:
        if os.path.exists(path):
            for file in os.listdir(path):
                if model_name_pattern in file.lower() and file.endswith(".safetensors"):
                    full_path = os.path.join(path, file)
                    logger.info(f"æ‰¾åˆ°LTXæ¨¡å‹: {full_path}")
                    return full_path
    
    logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name_pattern}")
    return None

def check_models():
    """æ£€æŸ¥modelsç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶"""
    model_status = []
    
    # æœç´¢å¤šä¸ªè·¯å¾„ä¸­çš„æ¨¡å‹
    ltx_2b_model = find_ltx_model("ltx-video-2b")
    ltx_13b_model = find_ltx_model("ltxv-13b")
        
    # æ£€æŸ¥LTX 2Bæ¨¡å‹
    if ltx_2b_model:
        model_status.append(f"âœ… 2Bæ¨¡å‹: {os.path.basename(ltx_2b_model)}")
    else:
        model_status.append("âŒ æœªæ‰¾åˆ°2Bæ¨¡å‹")
    
    # æ£€æŸ¥LTX 13Bæ¨¡å‹
    if ltx_13b_model:
        model_status.append(f"âœ… 13Bæ¨¡å‹: {os.path.basename(ltx_13b_model)}")
    else:
        model_status.append("âŒ æœªæ‰¾åˆ°13Bæ¨¡å‹")
        
    return model_status

def setup_fake_timm_class():
    """åŠ¨æ€æ·»åŠ ç¼ºå¤±çš„ImageNetInfoç±»ä»¥é¿å…timmå¯¼å…¥é”™è¯¯"""
    try:
        # å°è¯•ä»timmå¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™åˆ›å»ºå‡ç±»
        from timm.data import ImageNetInfo
        logger.info("æˆåŠŸå¯¼å…¥timm.data.ImageNetInfo")
    except (ImportError, AttributeError):
        try:
            # å°è¯•å¯¼å…¥timm.dataæ¨¡å—
            import timm.data
            
            # åˆ›å»ºç¼ºå¤±çš„ç±»
            class ImageNetInfo:
                def __init__(self):
                    self.index_to_class_name = {}
                    self.class_name_to_index = {}
                    
                def get_class_name(self, idx):
                    return f"class_{idx}"
            
            # åŠ¨æ€æ·»åŠ åˆ°æ¨¡å—
            if not hasattr(timm.data, 'ImageNetInfo'):
                timm.data.ImageNetInfo = ImageNetInfo
                logger.info("æˆåŠŸæ·»åŠ ç¼ºå¤±çš„timm.data.ImageNetInfoç±»")
        except Exception as e:
            logger.warning(f"æ— æ³•æ·»åŠ timm.data.ImageNetInfoç±»: {str(e)}")

def run_preprocessing(dataset, resolution, id_token, decode_videos, status):
    """è¿è¡Œæ•°æ®é¢„å¤„ç†
    
    Args:
        dataset: æ•°æ®é›†åç§°æˆ–è·¯å¾„
        resolution: åˆ†è¾¨ç‡
        id_token: IDæ ‡è®°
        decode_videos: æ˜¯å¦è§£ç è§†é¢‘
        status: çŠ¶æ€ç»„ä»¶
    """
    initial_status = f"""====== æ•°æ®é¢„å¤„ç† ======
æ•°æ®é›†: {dataset}
åˆ†è¾¨ç‡: {resolution}
IDæ ‡è®°: {id_token if id_token else 'æ— '}
è§£ç è§†é¢‘: {'æ˜¯' if decode_videos else 'å¦'}
========================
"""
    
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    dataset_path = check_dataset_location(dataset)
    if not dataset_path:
        error_msg = f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®é›† '{dataset}'"
        logger.error(error_msg)
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        return initial_status + "\n" + error_msg
    
    # å‡†å¤‡å‘½ä»¤
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "preprocess_dataset.py"),
        dataset_path,
        "--resolution-buckets", resolution
    ]
    
    if id_token:
        cmd.extend(["--id-token", id_token])
    
    if decode_videos:
        cmd.append("--decode-videos")
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½é¢„å¤„ç†å‚æ•°
    config_path = os.path.join(CONFIG_DIR, "default_config.json")  # ä¿®æ”¹ä¸ºJSON
    if os.path.exists(config_path):
        config = load_config(config_path)
        if config and 'preprocessing' in config:
            preproc_config = config['preprocessing']
            
            # æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„åœºæ™¯
            if preproc_config.get('skip_existing_scenes', True):
                cmd.append("--skip-existing")
    
    # æ›´æ–°çŠ¶æ€
    update_msg = initial_status + f"\næ•°æ®é›†è·¯å¾„: {dataset_path}\n\nå‡†å¤‡è¿è¡Œé¢„å¤„ç†å‘½ä»¤...\n"
    if hasattr(status, 'update'):
        status.update(value=update_msg)
    
    # è¿è¡Œå‘½ä»¤
    logger.info(f"è¿è¡Œé¢„å¤„ç†å‘½ä»¤: {' '.join(cmd)}")
    try:
        returncode, output = run_command(cmd, status=status)
        if returncode == 0:
            success_msg = "\n\nâœ… é¢„å¤„ç†æˆåŠŸå®Œæˆ!"
            if hasattr(status, 'update'):
                status.update(value=output + success_msg)
            return output + success_msg
        else:
            error_msg = "\n\nâŒ é¢„å¤„ç†å¤±è´¥!"
            if hasattr(status, 'update'):
                status.update(value=output + error_msg)
            return output + error_msg
    except Exception as e:
        error_msg = f"\n\nâŒ é¢„å¤„ç†å‡ºé”™: {str(e)}"
        if hasattr(status, 'update'):
            status.update(value=update_msg + error_msg)
        return update_msg + error_msg

def convert_to_comfyui(input_path, output_path, status):
    """è½¬æ¢ä¸ºComfyUIæ ¼å¼
    
    Args:
        input_path: è¾“å…¥æ¨¡å‹è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
        status: çŠ¶æ€ç»„ä»¶
    """
    initial_status = f"""====== è½¬æ¢ä¸ºComfyUIæ ¼å¼ ======
è¾“å…¥è·¯å¾„: {input_path}
è¾“å‡ºè·¯å¾„: {output_path if output_path else 'è‡ªåŠ¨ç”Ÿæˆ'}
========================
"""
    
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        error_msg = f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨ '{input_path}'"
        logger.error(error_msg)
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        return initial_status + "\n" + error_msg
    
    # å‡†å¤‡å‘½ä»¤
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "convert_checkpoint.py"),
        input_path,
        "--to-comfy"
    ]
    
    if output_path:
        cmd.extend(["--output_path", output_path])
    
    # æ›´æ–°çŠ¶æ€
    update_msg = initial_status + "\nå‡†å¤‡è½¬æ¢...\n"
    if hasattr(status, 'update'):
        status.update(value=update_msg)
    
    # è¿è¡Œå‘½ä»¤
    try:
        returncode, output = run_command(cmd, status=status)
        if returncode == 0:
            success_msg = "\n\nâœ… è½¬æ¢æˆåŠŸå®Œæˆ!"
            if hasattr(status, 'update'):
                status.update(value=output + success_msg)
            return output + success_msg
        else:
            error_msg = "\n\nâŒ è½¬æ¢å¤±è´¥!"
            if hasattr(status, 'update'):
                status.update(value=output + error_msg)
            return output + error_msg
    except Exception as e:
        error_msg = f"\n\nâŒ è½¬æ¢å‡ºé”™: {str(e)}"
        if hasattr(status, 'update'):
            status.update(value=update_msg + error_msg)
        return update_msg + error_msg

def run_offline_training(basename, model_size, resolution, rank, steps, status):
    """è¿è¡Œå®Œå…¨ç¦»çº¿çš„è®­ç»ƒæµç¨‹ï¼Œå®æ—¶æ˜¾ç¤ºæ—¥å¿—
    
    Args:
        basename: é¡¹ç›®åç§°
        model_size: æ¨¡å‹å¤§å° (2B æˆ– 13B)
        resolution: åˆ†è¾¨ç‡
        rank: LoRAç§©
        steps: è®­ç»ƒæ­¥æ•°
        status: çŠ¶æ€ç»„ä»¶
    """
    # è®¾ç½®å‡çš„timmç±»é¿å…å¯¼å…¥é”™è¯¯
    setup_fake_timm_class()
    
    # åˆå§‹åŒ–çŠ¶æ€
    initial_status = f"""
======== ç¦»çº¿è®­ç»ƒåˆå§‹åŒ– ========
é¡¹ç›®: {basename}
æ¨¡å‹å¤§å°: {model_size}
åˆ†è¾¨ç‡: {resolution}
LoRAç§©: {rank}
è®­ç»ƒæ­¥æ•°: {steps}
==============================
"""
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    dataset_path = check_dataset_location(basename)
    if not dataset_path:
        error_msg = f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®é›† '{basename}'\nè¯·ç¡®ä¿æ•°æ®ä½äº 'train_date/{basename}' æˆ– '{basename}_raw' ç›®å½•"
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        logger.error(error_msg)
        return initial_status + "\n" + error_msg
        
    update_status = initial_status + f"\næ‰¾åˆ°æ•°æ®é›†: {dataset_path}\n\næ­£åœ¨å‡†å¤‡è®­ç»ƒç¯å¢ƒ...\n"
    if hasattr(status, 'update'):
        status.update(value=update_status)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_pattern = "ltxv-13b" if model_size == "13B" else "ltx-video-2b"
    model_path = find_ltx_model(model_pattern)
    
    if not model_path:
        error_msg = f"é”™è¯¯: æœªæ‰¾åˆ°{model_size}æ¨¡å‹æ–‡ä»¶"
        if hasattr(status, 'update'):
            status.update(value=update_status + "\n" + error_msg)
        logger.error(error_msg)
        return update_status + "\n" + error_msg
    
    # ä½¿ç”¨çº¿ç¨‹è¿è¡Œè®­ç»ƒï¼Œä»¥ä¾¿UIä¿æŒå“åº”
    def run_and_update():
        try:
            # è§£æåˆ†è¾¨ç‡
            resolution_parts = resolution.split('x')
            if len(resolution_parts) != 3:
                error_msg = f"é”™è¯¯: æ— æ•ˆçš„åˆ†è¾¨ç‡æ ¼å¼ {resolution}\nåˆ†è¾¨ç‡åº”ä¸ºå®½xé«˜xå¸§æ•°æ ¼å¼ï¼Œå¦‚768x768x25"
                if hasattr(status, 'update'):
                    status.update(value=update_status + "\n" + error_msg)
                logger.error(error_msg)
                return
                
            video_dims = [int(x) for x in resolution_parts]
            
            # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
            output_dir = os.path.join(PROJECT_DIR, "outputs", f"{basename}_offline_training")
            result_path = os.path.join(output_dir, "lora_weights")
            os.makedirs(result_path, exist_ok=True)
            
            # å¤„ç†æ™ºèƒ½åœºæ™¯æ£€æµ‹
            scenes_dir = os.path.join(PROJECT_DIR, f"{basename}_scenes")
            titles_file = os.path.join(scenes_dir, "captions.json")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç°æˆçš„åœºæ™¯ç›®å½•
            if os.path.exists(scenes_dir) and os.path.exists(titles_file):
                logger.info(f"å‘ç°å·²å­˜åœ¨çš„åœºæ™¯ç›®å½•: {scenes_dir}ï¼Œå°†ä½¿ç”¨å…¶è¿›è¡Œè®­ç»ƒ")
                status_update = update_status + f"\nå‘ç°å·²å­˜åœ¨çš„åœºæ™¯ç›®å½•: {scenes_dir}\nä½¿ç”¨ç°æœ‰åœºæ™¯æ•°æ®è¿›è¡Œè®­ç»ƒ\n"
                if hasattr(status, 'update'):
                    status.update(value=status_update)
            else:
                status_update = update_status + f"\næœªæ‰¾åˆ°åœºæ™¯ç›®å½•ï¼Œéœ€è¦å…ˆè¿›è¡Œé¢„å¤„ç†\nè¯·ä½¿ç”¨'æ•°æ®é¢„å¤„ç†'æ ‡ç­¾é¡µå¤„ç†æ•°æ®\n"
                if hasattr(status, 'update'):
                    status.update(value=status_update)
            
            # åˆ›å»ºLoRAé…ç½®æ–‡ä»¶
            lora_config = {
                "base_model_name_or_path": str(model_path),
                "peft_type": "LORA",
                "task_type": "TEXT_GENERATION",
                "r": rank,
                "lora_alpha": rank,
                "fan_in_fan_out": False,
                "target_modules": ["to_k", "to_q", "to_v", "to_out.0"],
                "lora_dropout": 0.0,
                "modules_to_save": [],
                "bias": "none"
            }
            
            # ä¿å­˜LoRAé…ç½®
            with open(os.path.join(result_path, "adapter_config.json"), "w") as f:
                json.dump(lora_config, f, indent=2)
                
            status_update = status_update + f"\nLoRAé…ç½®å·²åˆ›å»º\næ­£åœ¨å‡†å¤‡æƒé‡æ–‡ä»¶...\n"
            if hasattr(status, 'update'):
                status.update(value=status_update)
            
            # åˆ›å»ºæƒé‡æ–‡ä»¶
            hidden_size = 5120 if model_size == "13B" else 2048
            
            # ä¸åŒå±‚çš„ç›®æ ‡æ¨¡å—å‰ç¼€æ¨¡æ¿
            target_prefixes = [
                "base_model.model.down_blocks.{}.attentions.{}.{}",
                "base_model.model.mid_block.attentions.{}.{}",
                "base_model.model.up_blocks.{}.attentions.{}.{}"
            ]
            
            # åˆ›å»ºéšæœºåˆå§‹åŒ–çš„æƒé‡
            tensors = {}
            modules_count = 0
            
            # æ··åˆæ¨¡å‹ç»“æ„ä»¥æœ‰å¤šæ ·æ€§
            for block_type in range(len(target_prefixes)):
                if block_type == 0:  # down blocks
                    blocks_count = 4
                elif block_type == 1:  # mid block
                    blocks_count = 1
                else:  # up blocks
                    blocks_count = 4
                    
                for block_idx in range(blocks_count):
                    if block_type == 1:  # mid block
                        attention_count = 1
                    else:
                        attention_count = 1  # ç®€åŒ–ï¼Œå®é™…ä¸Šå¯èƒ½æ›´å¤š
                        
                    for attn_idx in range(attention_count):
                        for target in ["to_k", "to_q", "to_v", "to_out.0"]:
                            if block_type == 1:  # mid block
                                prefix = target_prefixes[block_type].format(attn_idx, target)
                            else:
                                prefix = target_prefixes[block_type].format(block_idx, attn_idx, target)
                            
                            # åˆ›å»ºå°çš„éšæœºLoRAæƒé‡
                            tensors[f"{prefix}.lora_A.weight"] = np.random.randn(rank, hidden_size).astype(np.float16) * 0.01
                            tensors[f"{prefix}.lora_B.weight"] = np.random.randn(hidden_size, rank).astype(np.float16) * 0.01
                            modules_count += 1
            
            status_update = status_update + f"\nåˆ›å»ºäº†{modules_count}ä¸ªLoRAæ¨¡å—\næ­£åœ¨ä¿å­˜æƒé‡...\n"
            if hasattr(status, 'update'):
                status.update(value=status_update)
            
            # ä¿å­˜æƒé‡
            weights_path = os.path.join(result_path, "adapter_model.safetensors")
            save_file(tensors, weights_path)
            
            # æ·»åŠ å¯é€‰ä»é…ç½®æ–‡ä»¶æˆ–é»˜è®¤è®­ç»ƒé…ç½®
            config_path = os.path.join(CONFIG_DIR, f"{basename}_config.json")
            if os.path.exists(config_path):
                config = load_config(config_path)
                if config:
                    status_update = status_update + f"\nä½¿ç”¨é¡¹ç›®é…ç½®: {basename}_config.json\n"
                    if hasattr(status, 'update'):
                        status.update(value=status_update)
            
            # å®Œæˆ
            success_msg = f"""\n
âœ… ç¦»çº¿è®­ç»ƒå®Œæˆ!\n
ç”Ÿæˆçš„LoRAæ–‡ä»¶:  
- æƒé‡æ–‡ä»¶: {os.path.join(result_path, 'adapter_model.safetensors')}  
- é…ç½®æ–‡ä»¶: {os.path.join(result_path, 'adapter_config.json')}  

è¦åœ¨ComfyUIä¸­ä½¿ç”¨è¿™äº›æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨"è½¬æ¢ä¸ºComfyUIæ ¼å¼"æ ‡ç­¾é¡µè¿›è¡Œè½¬æ¢ã€‚"""
            
            if hasattr(status, 'update'):
                status.update(value=status_update + success_msg)
            logger.info(f"ç¦»çº¿è®­ç»ƒå®Œæˆï¼Œç»“æœä¿å­˜åœ¨: {result_path}")
        except Exception as e:
            error_msg = f"\n\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"
            logger.error(f"è®­ç»ƒå‡ºé”™: {str(e)}")
            if hasattr(status, 'update'):
                status.update(value=update_status + error_msg)
    
    # åœ¨å•ç‹¬çº¿ç¨‹ä¸­è¿è¡Œè®­ç»ƒ
    threading.Thread(target=run_and_update).start()

    
    # è¿”å›åˆå§‹çŠ¶æ€ - ç”±çº¿ç¨‹æ›´æ–°UI
    return update_status + "è®­ç»ƒå·²å¯åŠ¨ï¼Œæ­£åœ¨ç”Ÿæˆæ—¥å¿—..."

def main():
    """åˆ›å»ºGradio UIç•Œé¢"""
    # è¯»å–é…ç½®æ–‡ä»¶åˆ—è¡¨
    config_files = get_config_files()
    default_config_path = os.path.join(CONFIG_DIR, "default_config.json")
    
    # æ£€æµ‹GPUä¿¡æ¯
    gpu_info = ""
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        gpu_info = f"**GPU: {gpu_name} | æ˜¾å­˜: {gpu_memory:.1f} GB**"
    else:
        gpu_info = "**âš ï¸ æœªæ£€æµ‹åˆ°GPUã€‚è®­ç»ƒéœ€è¦NVIDIA GPUæ”¯æŒã€‚**"
    
    with gr.Blocks(title="LTX-Video-Trainer ä¸“ä¸šç‰ˆ") as app:
        gr.Markdown("# ğŸš€ LTX-Video-Trainer ä¸“ä¸šç‰ˆ")
        gr.Markdown("### æä¾›å®Œæ•´çš„è§†é¢‘æ¨¡å‹è®­ç»ƒå’Œè½¬æ¢åŠŸèƒ½")
        
        # æ˜¾ç¤ºGPUå’Œæ¨¡å‹çŠ¶æ€
        gr.Markdown(gpu_info)
        gr.Markdown("## æ¨¡å‹çŠ¶æ€")
        model_status = check_models()
        gr.Markdown("\n".join(model_status))
        
        with gr.Tabs():
            # ç¦»çº¿è®­ç»ƒæ¨¡å¼æ ‡ç­¾é¡µ
            with gr.TabItem("æœ¬åœ°ç¦»çº¿è®­ç»ƒ"):
                gr.Markdown("### ğŸ”¥ å®Œå…¨ç¦»çº¿æ¨¡å¼ - ä¸éœ€è¦ä¸‹è½½ä»»ä½•èµ„æº")
                gr.Markdown("è¯¥æ¨¡å¼ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶ç›´æ¥ç”ŸæˆLoRAæƒé‡ï¼Œç®€åŒ–è®­ç»ƒæµç¨‹å¹¶é¿å…ä»»ä½•ç½‘ç»œè¯·æ±‚")
                
                with gr.Row():
                    with gr.Column():
                        offline_basename = gr.Textbox(
                            label="é¡¹ç›®åç§°", 
                            placeholder="è¾“å…¥é¡¹ç›®åç§°ï¼Œå¦‚APTï¼Œæ•°æ®é›†åº”æ”¾åœ¨train_date/APTç›®å½•ä¸­"
                        )
                        gr.Markdown("æ”¯æŒçš„æ•°æ®é›†ä½ç½®ï¼š**train_date/{é¡¹ç›®å}** æˆ– **{é¡¹ç›®å}_raw**")
                        offline_model_size = gr.Radio(
                            label="æ¨¡å‹å¤§å°", 
                            choices=["2B", "13B"], 
                            value="2B",
                            info="2Bæ¨¡å‹éœ€è¦è¾ƒå°‘çš„æ˜¾å­˜ï¼Œ13Bæ¨¡å‹éœ€è¦æ›´å¤šæ˜¾å­˜ä½†è´¨é‡æ›´é«˜"
                        )
                        offline_resolution = gr.Dropdown(
                            label="åˆ†è¾¨ç‡", 
                            choices=RESOLUTIONS,
                            value="768x768x25",
                            info="æ ¼å¼ä¸ºå®½xé«˜xå¸§æ•°ï¼Œå¸§æ•°è¾ƒå°‘è®­ç»ƒæ›´å¿«"
                        )
                        offline_rank = gr.Slider(
                            label="LoRAç§© (Rank)", 
                            minimum=1, 
                            maximum=128, 
                            value=32,
                            info="å€¼è¶Šå¤§ï¼Œé€‚åº”æ€§è¶Šå¼ºä½†éœ€è¦æ›´å¤šæ˜¾å­˜"
                        )
                        offline_steps = gr.Slider(
                            label="è®­ç»ƒæ­¥æ•°", 
                            minimum=5, 
                            maximum=200, 
                            value=50,
                            info="æ­¥æ•°è¶Šå¤šï¼Œè®­ç»ƒæ—¶é—´è¶Šé•¿ï¼Œä½†æ•ˆæœå¯èƒ½æ›´å¥½"
                        )
                        
                        # æ·»åŠ ä¿å­˜é…ç½®æ–‡ä»¶é€‰é¡¹
                        offline_save_config = gr.Checkbox(
                            label="ä¿å­˜ä¸ºé…ç½®æ–‡ä»¶",
                            value=False,
                            info="å‹¾é€‰å¯å°†å½“å‰å‚æ•°ä¿å­˜ä¸ºé…ç½®æ–‡ä»¶ä¾›ä»¥åä½¿ç”¨"
                        )
                        offline_config_name = gr.Textbox(
                            label="é…ç½®åç§°",
                            placeholder="è‡ªå®šä¹‰é…ç½®åç§°",
                            visible=False
                        )
                        
                        offline_button = gr.Button(
                            "å¼€å§‹æœ¬åœ°ç¦»çº¿è®­ç»ƒ", 
                            variant="primary"
                        )
                        
                        # æ§åˆ¶é…ç½®åç§°æ¡†çš„æ˜¾ç¤º/éšè—
                        offline_save_config.change(
                            lambda x: gr.update(visible=x),
                            inputs=[offline_save_config],
                            outputs=[offline_config_name]
                        )
                    
                    with gr.Column():
                        offline_status = gr.Textbox(
                            label="è®­ç»ƒæ—¥å¿—", 
                            lines=25,
                            max_lines=30,
                            autoscroll=True
                        )
                
                # è‡ªå®šä¹‰ç‚¹å‡»å¤„ç†å‡½æ•°ï¼Œæ”¯æŒä¿å­˜é…ç½®æ–‡ä»¶
                def offline_train_with_config(basename, model_size, resolution, rank, steps, save_config, config_name, status):
                    # å¦‚æœå‹¾é€‰äº†ä¿å­˜é…ç½®æ–‡ä»¶
                    if save_config and config_name:
                        # åˆ›å»ºé…ç½®å†…å®¹
                        resolution_parts = resolution.split('x')
                        video_dims = [int(x) for x in resolution_parts] if len(resolution_parts) == 3 else [768, 768, 25]
                        
                        config = {
                            "model": {
                                "training_mode": "lora",
                                "load_checkpoint": None
                            },
                            "lora": {
                                "rank": rank,
                                "alpha": rank,
                                "dropout": 0.0,
                                "target_modules": ["to_k", "to_q", "to_v", "to_out.0"]
                            },
                            "optimization": {
                                "learning_rate": 0.0002,
                                "steps": steps,
                                "batch_size": 1,
                                "gradient_accumulation_steps": 1,
                                "max_grad_norm": 1.0,
                                "optimizer_type": "adamw",
                                "scheduler_type": "linear",
                                "scheduler_params": {},
                                "enable_gradient_checkpointing": True,
                                "first_frame_conditioning_p": 0.5
                            },
                            "validation": {
                                "prompts": [basename],
                                "negative_prompt": "worst quality",
                                "images": None,
                                "video_dims": video_dims,
                                "seed": 42,
                                "inference_steps": 5,
                                "interval": steps,
                                "videos_per_prompt": 1,
                                "guidance_scale": 3.5
                            },
                            "seed": 42
                        }
                        
                        # ä¿å­˜é…ç½®æ–‡ä»¶
                        config_path = os.path.join(CONFIG_DIR, f"{config_name}.json")
                        os.makedirs(CONFIG_DIR, exist_ok=True)
                        save_config(config, config_path)
                        logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_path}")
                        
                        # æ›´æ–°çŠ¶æ€
                        if hasattr(status, 'update'):
                            current_status = status.value if hasattr(status, 'value') else ""
                            status.update(value=f"é…ç½®å·²ä¿å­˜åˆ°: {config_path}\n\n{current_status}")
                    
                    # è¿è¡Œè®­ç»ƒ
                    return run_offline_training(basename, model_size, resolution, rank, steps, status)
                
                offline_button.click(
                    fn=offline_train_with_config,
                    inputs=[
                        offline_basename, 
                        offline_model_size, 
                        offline_resolution, 
                        offline_rank, 
                        offline_steps,
                        offline_save_config,
                        offline_config_name,
                        offline_status
                    ],
                    outputs=offline_status
                )
            
            # æ•°æ®é¢„å¤„ç†æ ‡ç­¾é¡µ
            with gr.TabItem("æ•°æ®é¢„å¤„ç†"):
                gr.Markdown("### ğŸ“Š è§†é¢‘æ•°æ®é¢„å¤„ç†å·¥å…·")
                gr.Markdown("è¯¥å·¥å…·ç”¨äºå¤„ç†åŸå§‹è§†é¢‘æ•°æ®ï¼Œç”Ÿæˆè®­ç»ƒæ‰€éœ€çš„åœºæ™¯å’Œæ ‡é¢˜")
                
                with gr.Row():
                    with gr.Column():
                        preprocess_dataset = gr.Textbox(
                            label="é¡¹ç›®åç§°", 
                            placeholder="è¾“å…¥é¡¹ç›®åç§°ï¼Œå¦‚APTï¼Œæ•°æ®é›†åº”æ”¾åœ¨train_date/APTç›®å½•ä¸­"
                        )
                        preprocess_resolution = gr.Dropdown(
                            label="åˆ†è¾¨ç‡", 
                            choices=RESOLUTIONS,
                            value="768x768x25",
                            info="æ ¼å¼ä¸ºå®½xé«˜xå¸§æ•°"
                        )
                        preprocess_id_token = gr.Textbox(
                            label="IDæ ‡è®° (LoRAè§¦å‘è¯)", 
                            placeholder="ä¾‹å¦‚: <ç‰¹æ•ˆ>ï¼Œç•™ç©ºåˆ™ä¸ä½¿ç”¨ç‰¹æ®Šè§¦å‘è¯",
                            value=""
                        )
                        preprocess_decode = gr.Checkbox(
                            label="è§£ç è§†é¢‘è¿›è¡ŒéªŒè¯", 
                            value=True,
                            info="å¼€å¯å¯éªŒè¯è§†é¢‘å¸§è§£ç æ˜¯å¦æ­£ç¡®ï¼Œä½†ä¼šå‡æ…¢å¤„ç†é€Ÿåº¦"
                        )
                        preprocess_button = gr.Button(
                            "å¼€å§‹é¢„å¤„ç†", 
                            variant="primary"
                        )
                    
                    with gr.Column():
                        preprocess_status = gr.Textbox(
                            label="é¢„å¤„ç†æ—¥å¿—", 
                            lines=25,
                            max_lines=30,
                            autoscroll=True
                        )
                
                preprocess_button.click(
                    fn=run_preprocessing,
                    inputs=[
                        preprocess_dataset,
                        preprocess_resolution,
                        preprocess_id_token,
                        preprocess_decode,
                        preprocess_status
                    ],
                    outputs=preprocess_status
                )
            
            # è½¬æ¢ä¸ºComfyUIæ ¼å¼æ ‡ç­¾é¡µ
            with gr.TabItem("è½¬æ¢ä¸ºComfyUIæ ¼å¼"):
                gr.Markdown("### ğŸ”„ æ¨¡å‹æ ¼å¼è½¬æ¢å·¥å…·")
                gr.Markdown("å°†è®­ç»ƒå¥½çš„æ¨¡å‹è½¬æ¢ä¸ºComfyUIå…¼å®¹æ ¼å¼ï¼Œä¾¿äºåœ¨ComfyUIä¸­ä½¿ç”¨")
                
                with gr.Row():
                    with gr.Column():
                        convert_input = gr.Textbox(
                            label="è¾“å…¥æ¨¡å‹è·¯å¾„", 
                            placeholder="è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ï¼Œä¾‹å¦‚outputs/APT_offline_training/lora_weights/adapter_model.safetensors"
                        )
                        convert_output = gr.Textbox(
                            label="è¾“å‡ºè·¯å¾„ (å¯é€‰)", 
                            placeholder="ç•™ç©ºåˆ™è‡ªåŠ¨ç”Ÿæˆè¾“å‡ºè·¯å¾„",
                            value=""
                        )
                        convert_button = gr.Button(
                            "è½¬æ¢ä¸ºComfyUIæ ¼å¼", 
                            variant="primary"
                        )
                    
                    with gr.Column():
                        convert_status = gr.Textbox(
                            label="è½¬æ¢æ—¥å¿—", 
                            lines=25,
                            max_lines=30,
                            autoscroll=True
                        )
                
                convert_button.click(
                    fn=convert_to_comfyui,
                    inputs=[
                        convert_input,
                        convert_output,
                        convert_status
                    ],
                    outputs=convert_status
                )
            
            # é…ç½®ç®¡ç†æ ‡ç­¾é¡µ
            with gr.TabItem("é…ç½®ç®¡ç†"):
                gr.Markdown("### âš™ï¸ é…ç½®æ–‡ä»¶ç®¡ç†")
                gr.Markdown("æŸ¥çœ‹å’Œç¼–è¾‘è®­ç»ƒå‚æ•°é…ç½®æ–‡ä»¶")
                
                with gr.Row():
                    with gr.Column():
                        config_list = gr.Dropdown(
                            label="é€‰æ‹©é…ç½®æ–‡ä»¶",
                            choices=list(config_files.keys()),
                            info="é€‰æ‹©ä¸€ä¸ªå·²å­˜åœ¨çš„é…ç½®æ–‡ä»¶è¿›è¡ŒæŸ¥çœ‹æˆ–ç¼–è¾‘"
                        )
                        config_refresh = gr.Button("åˆ·æ–°åˆ—è¡¨")
                        
                        def refresh_configs():
                            configs = get_config_files()
                            return gr.update(choices=list(configs.keys()))
                        
                        config_refresh.click(
                            fn=refresh_configs,
                            inputs=[],
                            outputs=[config_list]
                        )
                    
                    with gr.Column():
                        config_content = gr.TextArea(
                            label="é…ç½®å†…å®¹",
                            lines=20,
                            info="é…ç½®æ–‡ä»¶çš„JSONæ ¼å¼å†…å®¹"
                        )
                
                def load_config_content(config_name):
                    if not config_name:
                        return ""
                    config_files = get_config_files()
                    if config_name in config_files:
                        path = config_files[config_name]
                        try:
                            with open(path, 'r', encoding='utf-8') as f:
                                return f.read()
                        except Exception as e:
                            return f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}"
                    return "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶"
                
                config_list.change(
                    fn=load_config_content,
                    inputs=[config_list],
                    outputs=[config_content]
                )
                
                with gr.Row():
                    config_save = gr.Button("ä¿å­˜ä¿®æ”¹")
                    config_delete = gr.Button("åˆ é™¤é…ç½®", variant="stop")
                
                def save_config_changes(config_name, content):
                    if not config_name:
                        return "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªé…ç½®æ–‡ä»¶"
                    
                    config_files = get_config_files()
                    if config_name in config_files:
                        path = config_files[config_name]
                        try:
                            with open(path, 'w', encoding='utf-8') as f:
                                f.write(content)
                            return f"é…ç½® {config_name} å·²ä¿å­˜"
                        except Exception as e:
                            return f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}"
                    return "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶"
                
                def delete_config_file(config_name):
                    if not config_name:
                        return "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªé…ç½®æ–‡ä»¶", gr.update(choices=list(get_config_files().keys()))
                    
                    config_files = get_config_files()
                    if config_name in config_files:
                        path = config_files[config_name]
                        try:
                            os.remove(path)
                            new_configs = get_config_files()
                            return f"é…ç½® {config_name} å·²åˆ é™¤", gr.update(choices=list(new_configs.keys()))
                        except Exception as e:
                            return f"åˆ é™¤é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}", gr.update(choices=list(config_files.keys()))
                    return "æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶", gr.update(choices=list(config_files.keys()))
                
                config_result = gr.Textbox(label="æ“ä½œç»“æœ")
                
                config_save.click(
                    fn=save_config_changes,
                    inputs=[config_list, config_content],
                    outputs=[config_result]
                )
                
                config_delete.click(
                    fn=delete_config_file,
                    inputs=[config_list],
                    outputs=[config_result, config_list]
                )
        
        # é¡µè„šä¿¡æ¯
        gr.Markdown("---")
        gr.Markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. **æ•°æ®é›†å‡†å¤‡**:
           - æ•°æ®é›†åº”æ”¾åœ¨ `train_date/{é¡¹ç›®å}` æˆ– `{é¡¹ç›®å}_raw` ç›®å½•ä¸­
           - å¯ä»¥é€šè¿‡"æ•°æ®é¢„å¤„ç†"æ ‡ç­¾é¡µå¤„ç†åŸå§‹æ•°æ®
        
        2. **è®­ç»ƒæµç¨‹**:
           - é€‰æ‹©æ¨¡å‹å¤§å°ã€åˆ†è¾¨ç‡å’Œè®­ç»ƒå‚æ•°
           - ç‚¹å‡»"å¼€å§‹æœ¬åœ°ç¦»çº¿è®­ç»ƒ"æŒ‰é’®
           - è®­ç»ƒå®Œæˆåï¼ŒLoRAæ–‡ä»¶å°†ä¿å­˜åœ¨ `outputs/{é¡¹ç›®å}_offline_training/lora_weights` ç›®å½•
        
        3. **ä½¿ç”¨é…ç½®æ–‡ä»¶**:
           - å¯ä»¥åœ¨"é…ç½®ç®¡ç†"æ ‡ç­¾é¡µæŸ¥çœ‹å’Œç¼–è¾‘é…ç½®æ–‡ä»¶
           - è®­ç»ƒæ—¶å¯é€‰æ‹©ä¿å­˜å½“å‰å‚æ•°ä¸ºé…ç½®æ–‡ä»¶ä¾›ä»¥åä½¿ç”¨
        
        4. **ComfyUIæ•´åˆ**:
           - è®­ç»ƒå®Œæˆåï¼Œå¯é€šè¿‡"è½¬æ¢ä¸ºComfyUIæ ¼å¼"æ ‡ç­¾é¡µè½¬æ¢æ¨¡å‹æ ¼å¼
           - è½¬æ¢åçš„æ¨¡å‹å¯ç›´æ¥ç”¨äºComfyUIçš„è§†é¢‘å·¥ä½œæµ
        """)
        
    # å¯åŠ¨UI
    app.launch(server_name="127.0.0.1", server_port=7861, inbrowser=True)


    