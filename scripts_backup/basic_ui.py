#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
LTX-Video-Trainer æç®€Gradioç•Œé¢
é€‚åº”ä¸åŒç¯å¢ƒé…ç½®çš„ç®€åŒ–ç‰ˆUI
"""

import os
import sys
import subprocess
from pathlib import Path

# æ£€æŸ¥gradioæ˜¯å¦å¯ç”¨
try:
    import gradio as gr
    GRADIO_AVAILABLE = True
except ImportError:
    GRADIO_AVAILABLE = False
    print("è­¦å‘Š: Gradioæœªå®‰è£…ï¼Œå°†ä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢")

# æ£€æŸ¥torchæ˜¯å¦å¯ç”¨
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# é»˜è®¤è·¯å¾„
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CONFIGS_DIR = os.path.join(PROJECT_DIR, "configs")
SCRIPTS_DIR = os.path.join(PROJECT_DIR, "scripts")

# è¯»å–å¯ç”¨çš„é…ç½®æ–‡ä»¶
CONFIG_FILES = {}
for file in os.listdir(CONFIGS_DIR):
    if file.endswith(".yaml"):
        name = file.replace(".yaml", "")
        CONFIG_FILES[name] = os.path.join(CONFIGS_DIR, file)

# é¢„è®¾åˆ†è¾¨ç‡
RESOLUTIONS = [
    "512x512x25",
    "768x768x25", 
    "768x768x49",
    "1024x576x41"
]

def run_command(cmd, status_output=None):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºè¾“å‡º"""
    cmd_str = " ".join(cmd)
    
    if status_output:
        status_output.update(f"è¿è¡Œå‘½ä»¤:\n{cmd_str}\n\nè¯·ç­‰å¾…...")
    else:
        print(f"\næ‰§è¡Œå‘½ä»¤: {cmd_str}\n")
    
    try:
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )
        
        output_lines = []
        for line in process.stdout:
            line = line.strip()
            output_lines.append(line)
            
            if len(output_lines) > 50:
                output_lines = output_lines[-50:]  # ä¿ç•™æœ€å50è¡Œ
            
            if status_output:
                status_output.update(f"è¿è¡Œå‘½ä»¤:\n{cmd_str}\n\n" + "\n".join(output_lines))
            else:
                print(line)
        
        process.wait()
        
        result_msg = ""
        if process.returncode == 0:
            result_msg = "\nå‘½ä»¤æ‰§è¡ŒæˆåŠŸ!"
        else:
            result_msg = f"\nå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ä»£ç  {process.returncode}"
        
        if status_output:
            status_output.update(status_output.value + result_msg)
        else:
            print(result_msg)
            
        return True if process.returncode == 0 else False
    
    except Exception as e:
        error_msg = f"\næ‰§è¡Œå‡ºé”™: {str(e)}"
        if status_output:
            status_output.update(status_output.value + error_msg)
        else:
            print(error_msg)
        return False

def run_preprocessing(args):
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "preprocess_dataset.py"),
        args["dataset_path"],
        "--resolution-buckets", args["resolution"]
    ]
    
    if args.get("id_token"):
        cmd.extend(["--id-token", args["id_token"]])
    
    if args.get("decode_videos"):
        cmd.append("--decode-videos")
    
    return run_command(cmd, args.get("status_output"))

def run_training(args):
    """è¿è¡Œè®­ç»ƒè„šæœ¬"""
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "train.py"),
        args["config_path"]
    ]
    
    return run_command(cmd, args.get("status_output"))

def run_pipeline(args):
    """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "run_pipeline.py"),
        args["basename"],
        "--resolution-buckets", args["resolution"],
        "--config-template", args["config_template"],
        "--rank", str(args["rank"])
    ]
    
    return run_command(cmd, args.get("status_output"))

def convert_to_comfyui(args):
    """è½¬æ¢ä¸ºComfyUIæ ¼å¼"""
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "convert_checkpoint.py"),
        args["input_path"],
        "--to-comfy"
    ]
    
    if args.get("output_path"):
        cmd.extend(["--output_path", args["output_path"]])
    
    return run_command(cmd, args.get("status_output"))

def create_gradio_ui():
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="LTX-Videoè®­ç»ƒå™¨") as app:
        gr.Markdown("# ğŸ¬ LTX-Videoè®­ç»ƒå™¨")
        gr.Markdown("### è§†é¢‘æ¨¡å‹è®­ç»ƒç•Œé¢")
        
        # GPUä¿¡æ¯
        if TORCH_AVAILABLE and torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            gr.Markdown(f"**GPU: {gpu_name} | æ˜¾å­˜: {gpu_memory:.1f} GB**")
        else:
            gr.Markdown("**âš ï¸ æœªæ£€æµ‹åˆ°GPUæˆ–PyTorchã€‚è®­ç»ƒéœ€è¦NVIDIA GPUæ”¯æŒã€‚**")
        
        with gr.Tabs():
            # å®Œæ•´æµæ°´çº¿æ ‡ç­¾é¡µ
            with gr.Tab("ä¸€é”®è®­ç»ƒæµæ°´çº¿"):
                gr.Markdown("### ğŸš€ ä»åŸå§‹è§†é¢‘åˆ°è®­ç»ƒæ¨¡å‹çš„å…¨æµç¨‹")
                
                pipeline_basename = gr.Textbox(label="é¡¹ç›®åç§°", placeholder="ä¾‹å¦‚: my_effect")
                pipeline_resolution = gr.Dropdown(label="åˆ†è¾¨ç‡", choices=RESOLUTIONS, value="768x768x49")
                pipeline_config = gr.Dropdown(label="é…ç½®æ¨¡æ¿", choices=list(CONFIG_FILES.keys()))
                pipeline_rank = gr.Slider(label="LoRAç§© (Rank)", minimum=1, maximum=128, value=32)
                pipeline_status = gr.Textbox(label="çŠ¶æ€", interactive=False, lines=15)
                pipeline_button = gr.Button("å¼€å§‹ä¸€é”®è®­ç»ƒ", variant="primary")
                
                def run_pipeline_ui(basename, resolution, config_template, rank):
                    if not basename:
                        return "é”™è¯¯: é¡¹ç›®åç§°ä¸èƒ½ä¸ºç©º"
                    
                    args = {
                        "basename": basename,
                        "resolution": resolution,
                        "config_template": CONFIG_FILES.get(config_template),
                        "rank": rank,
                        "status_output": pipeline_status
                    }
                    
                    run_pipeline(args)
                    return pipeline_status.value
                
                pipeline_button.click(
                    run_pipeline_ui,
                    inputs=[pipeline_basename, pipeline_resolution, pipeline_config, pipeline_rank],
                    outputs=pipeline_status
                )
            
            # æ•°æ®é¢„å¤„ç†æ ‡ç­¾é¡µ
            with gr.Tab("æ•°æ®é¢„å¤„ç†"):
                gr.Markdown("### ğŸ”„ å‡†å¤‡æ•°æ®é›†")
                
                preprocess_dataset = gr.Textbox(label="æ•°æ®é›†è·¯å¾„", placeholder="æ•°æ®é›†ç›®å½•æˆ–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„")
                preprocess_resolution = gr.Dropdown(label="åˆ†è¾¨ç‡", choices=RESOLUTIONS, value="768x768x25")
                preprocess_id_token = gr.Textbox(label="IDæ ‡è®° (LoRAè§¦å‘è¯)", placeholder="ä¾‹å¦‚: <ç‰¹æ•ˆ>")
                preprocess_decode = gr.Checkbox(label="è§£ç è§†é¢‘è¿›è¡ŒéªŒè¯", value=True)
                preprocess_status = gr.Textbox(label="çŠ¶æ€", interactive=False, lines=15)
                preprocess_button = gr.Button("å¼€å§‹é¢„å¤„ç†", variant="primary")
                
                def run_preprocess_ui(dataset_path, resolution, id_token, decode_videos):
                    if not dataset_path:
                        return "é”™è¯¯: æ•°æ®é›†è·¯å¾„ä¸èƒ½ä¸ºç©º"
                    
                    args = {
                        "dataset_path": dataset_path,
                        "resolution": resolution,
                        "id_token": id_token,
                        "decode_videos": decode_videos,
                        "status_output": preprocess_status
                    }
                    
                    run_preprocessing(args)
                    return preprocess_status.value
                
                preprocess_button.click(
                    run_preprocess_ui,
                    inputs=[preprocess_dataset, preprocess_resolution, preprocess_id_token, preprocess_decode],
                    outputs=preprocess_status
                )
            
            # æ¨¡å‹è®­ç»ƒæ ‡ç­¾é¡µ
            with gr.Tab("æ¨¡å‹è®­ç»ƒ"):
                gr.Markdown("### ğŸš‚ è®­ç»ƒæ¨¡å‹")
                
                train_config = gr.Dropdown(label="è®­ç»ƒé…ç½®æ–‡ä»¶", choices=list(CONFIG_FILES.keys()))
                train_status = gr.Textbox(label="çŠ¶æ€", interactive=False, lines=15)
                train_button = gr.Button("å¼€å§‹è®­ç»ƒ", variant="primary")
                
                def run_train_ui(config_name):
                    if not config_name:
                        return "é”™è¯¯: è¯·é€‰æ‹©é…ç½®æ–‡ä»¶"
                    
                    args = {
                        "config_path": CONFIG_FILES.get(config_name),
                        "status_output": train_status
                    }
                    
                    run_training(args)
                    return train_status.value
                
                train_button.click(
                    run_train_ui,
                    inputs=[train_config],
                    outputs=train_status
                )
            
            # è½¬æ¢æ ‡ç­¾é¡µ
            with gr.Tab("è½¬æ¢ä¸ºComfyUIæ ¼å¼"):
                gr.Markdown("### ğŸ”„ è½¬æ¢æ¨¡å‹æ ¼å¼")
                
                convert_input = gr.Textbox(label="è¾“å…¥æ¨¡å‹è·¯å¾„", placeholder="è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ (.safetensors)")
                convert_output = gr.Textbox(label="è¾“å‡ºè·¯å¾„ (å¯é€‰)", placeholder="ç•™ç©ºåˆ™è‡ªåŠ¨å‘½å")
                convert_status = gr.Textbox(label="çŠ¶æ€", interactive=False, lines=10)
                convert_button = gr.Button("è½¬æ¢ä¸ºComfyUIæ ¼å¼", variant="primary")
                
                def run_convert_ui(input_path, output_path):
                    if not input_path:
                        return "é”™è¯¯: è¾“å…¥è·¯å¾„ä¸èƒ½ä¸ºç©º"
                    
                    args = {
                        "input_path": input_path,
                        "output_path": output_path,
                        "status_output": convert_status
                    }
                    
                    convert_to_comfyui(args)
                    return convert_status.value
                
                convert_button.click(
                    run_convert_ui,
                    inputs=[convert_input, convert_output],
                    outputs=convert_status
                )
            
            # å¸®åŠ©æ ‡ç­¾é¡µ
            with gr.Tab("å¸®åŠ©"):
                gr.Markdown("""
                # LTX-Video-Trainer ä½¿ç”¨å¸®åŠ©
                
                ## è®­ç»ƒæ•°æ®è¦æ±‚
                
                - **æ•°é‡**: é€šå¸¸5-50ä¸ªè§†é¢‘æ•ˆæœçš„æ ·æœ¬å³å¯
                - **é•¿åº¦**: æ¨è5-15ç§’çš„çŸ­è§†é¢‘ç‰‡æ®µ
                - **è´¨é‡**: é«˜è´¨é‡ã€æ¸…æ™°çš„è§†é¢‘æ•ˆæœæ ·æœ¬
                - **å†…å®¹**: é›†ä¸­å±•ç¤ºæ‚¨æƒ³è¦è®­ç»ƒçš„ç‰¹æ•ˆ
                
                ## ç¡¬ä»¶è¦æ±‚
                
                - **GPU**: è‡³å°‘24GBæ˜¾å­˜çš„NVIDIA GPU (ç”¨äº2Bæ¨¡å‹)
                - **CPU**: å¤šæ ¸å¤„ç†å™¨
                - **å†…å­˜**: è‡³å°‘16GB RAM
                - **å­˜å‚¨**: è‡³å°‘50GBå¯ç”¨ç©ºé—´
                
                ## å¿«é€Ÿå¼€å§‹æŒ‡å—
                
                ### ä½¿ç”¨ä¸€é”®æµæ°´çº¿:
                
                1. åˆ›å»ºåä¸º`é¡¹ç›®å_raw`çš„æ–‡ä»¶å¤¹
                2. å°†åŸå§‹è§†é¢‘æ”¾å…¥è¯¥æ–‡ä»¶å¤¹
                3. åœ¨ç•Œé¢ä¸­å¡«å†™é¡¹ç›®åç§°(ä¸å«"_raw"åç¼€)
                4. é€‰æ‹©åˆ†è¾¨ç‡å’Œé…ç½®æ¨¡æ¿
                5. ç‚¹å‡»"å¼€å§‹ä¸€é”®è®­ç»ƒ"
                
                ### ä½¿ç”¨è‡ªå®šä¹‰å·¥ä½œæµ:
                
                1. **æ•°æ®é¢„å¤„ç†**:
                   - æä¾›æ•°æ®é›†è·¯å¾„(è§†é¢‘æ–‡ä»¶å¤¹æˆ–å…ƒæ•°æ®æ–‡ä»¶)
                   - é€‰æ‹©åˆ†è¾¨ç‡
                   - è®¾ç½®LoRAè§¦å‘è¯(å¯é€‰)
                   - ç‚¹å‡»"å¼€å§‹é¢„å¤„ç†"
                
                2. **æ¨¡å‹è®­ç»ƒ**:
                   - é€‰æ‹©é…ç½®æ–‡ä»¶
                   - ç‚¹å‡»"å¼€å§‹è®­ç»ƒ"
                
                3. **è½¬æ¢æ ¼å¼**:
                   - æä¾›è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶è·¯å¾„
                   - ç‚¹å‡»"è½¬æ¢ä¸ºComfyUIæ ¼å¼"
                
                ## åˆ†è¾¨ç‡é€‰æ‹©æŒ‡å—
                
                åˆ†è¾¨ç‡æ ¼å¼ä¸º"å®½xé«˜xå¸§æ•°":
                
                - **512x512x25**: åŸºç¡€åˆ†è¾¨ç‡ï¼Œé€‚åˆä½æ˜¾å­˜
                - **768x768x25**: ä¸­ç­‰åˆ†è¾¨ç‡ï¼Œæ›´å¥½çš„ç»†èŠ‚
                - **768x768x49**: æ›´å¤šå¸§æ•°ï¼Œæ•æ‰æ›´å¤šåŠ¨æ€
                - **1024x576x41**: å®½å±æ ¼å¼ï¼Œé«˜æ¸…ç»†èŠ‚
                """)
        
        gr.Markdown("*æ„Ÿè°¢ä½¿ç”¨LTX-Videoè®­ç»ƒå™¨*")
    
    return app

def run_cli():
    """è¿è¡Œå‘½ä»¤è¡Œç•Œé¢"""
    while True:
        print("\n===== LTX-Videoè®­ç»ƒå™¨ =====")
        print("1. ä¸€é”®è®­ç»ƒæµæ°´çº¿")
        print("2. æ•°æ®é¢„å¤„ç†")
        print("3. æ¨¡å‹è®­ç»ƒ")
        print("4. è½¬æ¢ä¸ºComfyUIæ ¼å¼")
        print("5. ä½¿ç”¨å¸®åŠ©")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æ“ä½œ (è¾“å…¥ç¼–å·): ")
        
        if choice == "1":
            print("\n===== ä¸€é”®è®­ç»ƒæµæ°´çº¿ =====")
            basename = input("\né¡¹ç›®åç§° (ä¾‹å¦‚: my_effect): ")
            
            print("\nå¯ç”¨åˆ†è¾¨ç‡:")
            for i, res in enumerate(RESOLUTIONS, 1):
                print(f"{i}. {res}")
            
            res_choice = int(input("\né€‰æ‹©åˆ†è¾¨ç‡ (è¾“å…¥ç¼–å·): "))
            resolution = RESOLUTIONS[res_choice - 1]
            
            print("\nå¯ç”¨é…ç½®æ¨¡æ¿:")
            config_names = list(CONFIG_FILES.keys())
            for i, name in enumerate(config_names, 1):
                print(f"{i}. {name}")
            
            config_choice = int(input("\né€‰æ‹©é…ç½®æ¨¡æ¿ (è¾“å…¥ç¼–å·): "))
            config_template = CONFIG_FILES[config_names[config_choice - 1]]
            
            rank = int(input("\nLoRAç§© (1-128ï¼Œæ¨è32): ") or "32")
            
            args = {
                "basename": basename,
                "resolution": resolution,
                "config_template": config_template,
                "rank": rank
            }
            
            run_pipeline(args)
        
        elif choice == "2":
            print("\n===== æ•°æ®é¢„å¤„ç† =====")
            dataset_path = input("\næ•°æ®é›†è·¯å¾„ (æ–‡ä»¶å¤¹æˆ–å…ƒæ•°æ®æ–‡ä»¶): ")
            
            print("\nå¯ç”¨åˆ†è¾¨ç‡:")
            for i, res in enumerate(RESOLUTIONS, 1):
                print(f"{i}. {res}")
            
            res_choice = int(input("\né€‰æ‹©åˆ†è¾¨ç‡ (è¾“å…¥ç¼–å·): "))
            resolution = RESOLUTIONS[res_choice - 1]
            
            id_token = input("\nLoRAè§¦å‘è¯ (å¯é€‰ï¼ŒæŒ‰Enterè·³è¿‡): ")
            decode_videos = input("\nè§£ç è§†é¢‘è¿›è¡ŒéªŒè¯? (y/n): ").lower() == "y"
            
            args = {
                "dataset_path": dataset_path,
                "resolution": resolution,
                "id_token": id_token,
                "decode_videos": decode_videos
            }
            
            run_preprocessing(args)
        
        elif choice == "3":
            print("\n===== æ¨¡å‹è®­ç»ƒ =====")
            
            print("\nå¯ç”¨é…ç½®:")
            config_names = list(CONFIG_FILES.keys())
            for i, name in enumerate(config_names, 1):
                print(f"{i}. {name}")
            
            config_choice = int(input("\né€‰æ‹©é…ç½® (è¾“å…¥ç¼–å·): "))
            config_path = CONFIG_FILES[config_names[config_choice - 1]]
            
            args = {
                "config_path": config_path
            }
            
            run_training(args)
        
        elif choice == "4":
            print("\n===== è½¬æ¢ä¸ºComfyUIæ ¼å¼ =====")
            
            input_path = input("\nè¾“å…¥æ¨¡å‹è·¯å¾„ (.safetensors): ")
            output_path = input("\nè¾“å‡ºè·¯å¾„ (å¯é€‰ï¼ŒæŒ‰Enterè·³è¿‡): ")
            
            args = {
                "input_path": input_path,
                "output_path": output_path
            }
            
            convert_to_comfyui(args)
        
        elif choice == "5":
            print("""
            ===== LTX-Video-Trainer ä½¿ç”¨å¸®åŠ© =====
            
            è®­ç»ƒè¦æ±‚:
            - ç¡¬ä»¶: æ¨èä½¿ç”¨è‡³å°‘24GBæ˜¾å­˜çš„NVIDIA GPU
            - è®­ç»ƒæ•°æ®: 5-50ä¸ªçŸ­è§†é¢‘ç‰‡æ®µ (æ¯ä¸ª5-15ç§’)
            - è®­ç»ƒæ—¶é—´: å–å†³äºæ•°æ®é›†å¤§å°ã€è®­ç»ƒè½®æ•°å’ŒGPUæ€§èƒ½
            
            å¿«é€Ÿå¼€å§‹:
            1. ä¸€é”®è®­ç»ƒæµæ°´çº¿
               - åˆ›å»ºåä¸º`é¡¹ç›®åç§°_raw`çš„æ–‡ä»¶å¤¹ï¼Œå°†è§†é¢‘æ”¾å…¥å…¶ä¸­
               - è¿è¡Œä¸€é”®è®­ç»ƒæµæ°´çº¿ï¼Œå¡«å†™é¡¹ç›®åç§°ï¼ˆä¸å«"_raw"åç¼€ï¼‰
            
            2. è‡ªå®šä¹‰å·¥ä½œæµ
               - é¢„å¤„ç†: å‡†å¤‡å¹¶å¤„ç†æ•°æ®é›†
               - è®­ç»ƒ: é…ç½®å¹¶è¿è¡Œè®­ç»ƒ
               - è½¬æ¢: å°†è®­ç»ƒå¥½çš„æƒé‡è½¬æ¢ä¸ºComfyUIæ ¼å¼
            
            æ•°æ®é›†å‡†å¤‡å»ºè®®:
            - ä½¿ç”¨5-15ç§’çš„çŸ­ç‰‡å±•ç¤ºä½ æƒ³è¦è®­ç»ƒçš„æ•ˆæœ
            - ç¡®ä¿è§†é¢‘å…·æœ‰ä¸€è‡´çš„è´¨é‡å’Œé£æ ¼
            - æœ€å¥½ä½¿ç”¨å¤šä¸ªä¸åŒè§’åº¦/åœºæ™¯çš„æ•ˆæœç¤ºä¾‹
            
            é…ç½®å»ºè®®:
            - åˆ†è¾¨ç‡: æ›´é«˜çš„åˆ†è¾¨ç‡éœ€è¦æ›´å¤šæ˜¾å­˜ä½†èƒ½æ•æ‰æ›´å¤šç»†èŠ‚
            - è®­ç»ƒè½®æ•°: ä»100-200è½®å¼€å§‹ï¼Œæ ¹æ®ç»“æœè°ƒæ•´
            - LoRAç§©: æ›´é«˜çš„ç§©(16-64)èƒ½æ•æ‰æ›´å¤æ‚çš„æ•ˆæœï¼Œä½†éœ€è¦æ›´å¤šæ•°æ®
            
            åˆ†è¾¨ç‡é€‰æ‹©æŒ‡å—:
            åˆ†è¾¨ç‡æ ¼å¼ä¸º"å®½xé«˜xå¸§æ•°"ï¼Œä¾‹å¦‚"768x768x49"ï¼Œå…¶ä¸­:
            - å®½åº¦å’Œé«˜åº¦å¿…é¡»æ˜¯32çš„å€æ•°
            - å¸§æ•°å¿…é¡»æ˜¯8çš„å€æ•°åŠ 1ï¼ˆå¦‚9ã€17ã€25ã€33ç­‰ï¼‰
            """)
        
        elif choice == "0":
            print("\næ„Ÿè°¢ä½¿ç”¨LTX-Videoè®­ç»ƒå™¨!")
            break
        
        else:
            print("\næ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡è¯•ã€‚")

if __name__ == "__main__":
    # å°è¯•ä½¿ç”¨Gradioç•Œé¢ï¼Œå¦‚æœä¸å¯ç”¨åˆ™å›é€€åˆ°å‘½ä»¤è¡Œ
    if GRADIO_AVAILABLE:
        try:
            app = create_gradio_ui()
            print("æ­£åœ¨å¯åŠ¨Gradioç•Œé¢...")
            app.launch(share=False)
        except Exception as e:
            print(f"å¯åŠ¨Gradioç•Œé¢å¤±è´¥: {str(e)}")
            print("å›é€€åˆ°å‘½ä»¤è¡Œç•Œé¢")
            run_cli()
    else:
        print("æœªæ£€æµ‹åˆ°Gradioï¼Œä½¿ç”¨å‘½ä»¤è¡Œç•Œé¢...")
        run_cli()
