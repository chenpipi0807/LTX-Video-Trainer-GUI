#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
å¢å¼ºç‰ˆUIç•Œé¢ï¼Œä¸“æ³¨äºç¦»çº¿è®­ç»ƒåŠŸèƒ½
æä¾›è¯¦ç»†çš„è®­ç»ƒæ—¥å¿—è¾“å‡ºå’Œè¿›åº¦åé¦ˆ
æ”¯æŒé…ç½®æ–‡ä»¶ã€æ•°æ®é¢„å¤„ç†å’ŒComfyUIæ ¼å¼è½¬æ¢
"""

import os
import sys
import logging
import json
import yaml
import threading
import subprocess
import numpy as np
import torch
import gradio as gr
from pathlib import Path
from safetensors.numpy import save_file

# è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ç¦»çº¿æ¨¡å¼
os.environ["PYTHONIOENCODING"] = "utf8"
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"

# è·å–é¡¹ç›®æ ¹ç›®å½•å’Œå…¶ä»–é‡è¦ç›®å½•
PROJECT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
SCRIPTS_DIR = os.path.join(PROJECT_DIR, "scripts")
CONFIG_DIR = os.path.join(PROJECT_DIR, "config")
DATA_DIR = os.path.join(PROJECT_DIR, "train_date")

sys.path.append(PROJECT_DIR)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger('LTX-Trainer')

# åˆ†è¾¨ç‡é€‰é¡¹
RESOLUTIONS = [
    "512x512x25", "576x576x25", "640x640x25", "704x704x25", "768x768x25",
    "512x512x49", "576x576x49", "640x640x49", "704x704x49", "768x768x49",
    "576x1024x41", "1024x576x41"
]

# å¯èƒ½çš„LTXæ¨¡å‹è·¯å¾„
POSSIBLE_MODEL_PATHS = [
    # é¡¹ç›®å†…éƒ¨è·¯å¾„
    os.path.join(PROJECT_DIR, "models"),
    # ComfyUIè·¯å¾„
    r"C:\NEWCOMFYUI\ComfyUI_windows_portable\ComfyUI\models\checkpoints",
]

# è¯»å–é…ç½®æ–‡ä»¶
def load_config(config_path):
    """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

# ä¿å­˜é…ç½®æ–‡ä»¶
def save_config(config, config_path):
    """ä¿å­˜é…ç½®åˆ°YAMLæ–‡ä»¶"""
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False)
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

# è·å–æ‰€æœ‰é…ç½®æ–‡ä»¶
def get_config_files():
    """è¯»å–å¯ç”¨çš„é…ç½®æ–‡ä»¶"""
    config_files = {}
    try:
        if os.path.exists(CONFIG_DIR):
            for file in os.listdir(CONFIG_DIR):
                if file.endswith(".yaml"):
                    name = file.replace(".yaml", "")
                    config_files[name] = os.path.join(CONFIG_DIR, file)
        return config_files
    except Exception as e:
        logger.error(f"è¯»å–é…ç½®æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
        return {}

def check_dataset_location(basename):
    """æ£€æŸ¥æ•°æ®é›†ä½ç½®å¹¶è¿”å›æœ‰æ•ˆçš„è·¯å¾„"""
    # é¦–å…ˆæ£€æŸ¥train_dateç›®å½•
    train_date_path = os.path.join(PROJECT_DIR, "train_date", basename)
    if os.path.exists(train_date_path) and os.listdir(train_date_path):
        logger.info(f"æ‰¾åˆ°train_dateç›®å½•ä¸‹çš„æ•°æ®é›†: {train_date_path}")
        return train_date_path
        
    # ç„¶åæ£€æŸ¥é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„_rawç›®å½•
    raw_path = os.path.join(PROJECT_DIR, f"{basename}_raw")
    if os.path.exists(raw_path) and os.listdir(raw_path):
        logger.info(f"æ‰¾åˆ°åŸå§‹ç»“æ„æ•°æ®é›†: {raw_path}")
        return raw_path
        
    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œè¿”å›None
    return None

def run_command(command, status=None, verbose=True):
    """è¿è¡Œå‘½ä»¤å¹¶å®æ—¶æ›´æ–°çŠ¶æ€"""
    process = subprocess.Popen(
        command,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True,
        bufsize=1,
        universal_newlines=True
    )
    
    output = []
    for line in process.stdout:
        if verbose:
            print(line, end='')
        output.append(line.strip())
        if status and hasattr(status, 'update') and len(output) % 5 == 0:
            status.update(value="\n".join(output[-25:]))
    
    process.wait()
    return process.returncode, "\n".join(output)

def run_offline_training(basename, model_size, resolution, rank, steps, status):
    """
    è¿è¡Œå®Œå…¨ç¦»çº¿çš„è®­ç»ƒæµç¨‹ï¼Œå®æ—¶æ˜¾ç¤ºæ—¥å¿—
    
    Args:
        basename: é¡¹ç›®åç§°
        model_size: æ¨¡å‹å¤§å° (2B æˆ– 13B)
        resolution: åˆ†è¾¨ç‡
        rank: LoRAç§©
        steps: è®­ç»ƒæ­¥æ•°
        status: çŠ¶æ€ç»„ä»¶
    """
    # åˆå§‹åŒ–çŠ¶æ€
    initial_status = f"""
======== ç¦»çº¿è®­ç»ƒåˆå§‹åŒ– ========
é¡¹ç›®: {basename}
æ¨¡å‹å¤§å°: {model_size}
åˆ†è¾¨ç‡: {resolution}
LoRAç§©: {rank}
è®­ç»ƒæ­¥æ•°: {steps}
==============================
"""
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    dataset_path = check_dataset_location(basename)
    if not dataset_path:
        error_msg = f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®é›† '{basename}'\nè¯·ç¡®ä¿æ•°æ®ä½äº 'train_date/{basename}' æˆ– '{basename}_raw' ç›®å½•"
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        logger.error(error_msg)
        return initial_status + "\n" + error_msg
        
    update_status = initial_status + f"\næ‰¾åˆ°æ•°æ®é›†: {dataset_path}\n\næ­£åœ¨å‡†å¤‡è®­ç»ƒç¯å¢ƒ...\n"
    if hasattr(status, 'update'):
        status.update(value=update_status)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    model_pattern = "ltxv-13b" if model_size == "13B" else "ltx-video-2b"
    models_dir = os.path.join(PROJECT_DIR, "models")
    model_files = list(Path(models_dir).glob(f"*{model_pattern}*.safetensors"))
    
    if not model_files:
        error_msg = f"é”™è¯¯: åœ¨modelsç›®å½•ä¸­æœªæ‰¾åˆ°{model_size}æ¨¡å‹æ–‡ä»¶"
        if hasattr(status, 'update'):
            status.update(value=update_status + "\n" + error_msg)
        logger.error(error_msg)
        return update_status + "\n" + error_msg
    
    model_path = model_files[0]
    logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
    update_status += f"ä½¿ç”¨æ¨¡å‹: {model_path}\n\nå¼€å§‹è®­ç»ƒè¿‡ç¨‹..."
    
    if hasattr(status, 'update'):
        status.update(value=update_status)
    
    # è·å–å¢å¼ºç‰ˆè®­ç»ƒè„šæœ¬è·¯å¾„
    enhanced_script_path = os.path.join(PROJECT_DIR, "scripts", "enhanced_offline_train.py")
    
    # ç»„è£…å‘½ä»¤
    cmd = [
        sys.executable,
        enhanced_script_path,
        basename,
        "--model-size", model_size,
        "--resolution", resolution,
        "--rank", str(rank),
        "--steps", str(steps)
    ]
    
    # æ‰“å°å‘½ä»¤
    cmd_line = " ".join(cmd)
    logger.info(f"æ‰§è¡Œå‘½ä»¤: {cmd_line}")
    update_status += f"\n\næ‰§è¡Œå‘½ä»¤: {cmd_line}\n\n== è®­ç»ƒæ—¥å¿—å¼€å§‹ ==\n"
    
    if hasattr(status, 'update'):
        status.update(value=update_status)
    
    # è¿è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡º
    def run_and_update():
        nonlocal update_status
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=False,  # ä½¿ç”¨bytesæ¨¡å¼è€Œä¸æ˜¯textæ¨¡å¼
            bufsize=1
            # ç§»é™¤universal_newlines=Trueä»¥é¿å…é»˜è®¤ç¼–ç é—®é¢˜
        )
        
        output_lines = []
        for line in process.stdout:
            # ä½¿ç”¨utf-8è§£ç ï¼Œå¿½ç•¥æ— æ³•è§£ç çš„å­—ç¬¦
            try:
                decoded_line = line.decode('utf-8', errors='replace').strip()
                print(decoded_line)  # åœ¨æ§åˆ¶å°æ˜¾ç¤º
                output_lines.append(decoded_line)
            except Exception as e:
                # å¦‚æœå‡ºé”™ï¼Œè½¬æ¢ä¸ºå®‰å…¨çš„å­—ç¬¦ä¸²
                safe_line = str(line).replace('\\', '/').strip()
                print(f"[è§£ç é”™è¯¯] {safe_line}")
                output_lines.append(f"[è§£ç é”™è¯¯] {safe_line}")
            
            # æ›´æ–°UIçŠ¶æ€ - ä¿æŒæœ€æ–°çš„25è¡Œ
            if len(output_lines) <= 30:
                current_status = update_status + "\n".join(output_lines)
            else:
                # ä¿ç•™å¼€å¤´å’Œæœ€æ–°çš„æ—¥å¿—
                current_status = update_status + "...\n" + "\n".join(output_lines[-25:])
            
            if hasattr(status, 'update'):
                status.update(value=current_status)
        
        process.wait()
        
        if process.returncode == 0:
            final_status = update_status + "\n".join(output_lines) + "\n\n== è®­ç»ƒæ—¥å¿—ç»“æŸ ==\n\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆ!\n"
            final_status += f"ç»“æœä¿å­˜åœ¨: outputs/{basename}_offline_training/lora_weights/\n"
            final_status += "åŒ…å«ä»¥ä¸‹æ–‡ä»¶:\n"
            final_status += "- adapter_model.safetensors (LoRAæƒé‡)\n"
            final_status += "- adapter_config.json (LoRAé…ç½®)\n"
        else:
            final_status = update_status + "\n".join(output_lines) + "\n\n== è®­ç»ƒæ—¥å¿—ç»“æŸ ==\n\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™!\n"
            final_status += f"é€€å‡ºç : {process.returncode}\n"
            
        if hasattr(status, 'update'):
            status.update(value=final_status)
            
    # ä½¿ç”¨çº¿ç¨‹æ‰§è¡Œè®­ç»ƒ
    thread = threading.Thread(target=run_and_update)
    thread.daemon = True
    thread.start()
    
    # è¿”å›åˆå§‹çŠ¶æ€ - ç”±çº¿ç¨‹æ›´æ–°UI
    return update_status + "è®­ç»ƒå·²å¯åŠ¨ï¼Œæ­£åœ¨ç”Ÿæˆæ—¥å¿—..."

def find_ltx_model(model_name_pattern="ltxv-13b"):
    """æŸ¥æ‰¾LTXæ¨¡å‹æ–‡ä»¶
    
    Args:
        model_name_pattern: æ¨¡å‹åç§°æ¨¡å¼ï¼Œå¦‚ltxv-13b
        
    Returns:
        æ‰¾åˆ°çš„æ¨¡å‹è·¯å¾„æˆ–None
    """
    for path in POSSIBLE_MODEL_PATHS:
        if os.path.exists(path):
            for file in os.listdir(path):
                if model_name_pattern in file.lower() and file.endswith(".safetensors"):
                    full_path = os.path.join(path, file)
                    logger.info(f"æ‰¾åˆ°LTXæ¨¡å‹: {full_path}")
                    return full_path
    
    logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_name_pattern}")
    return None

def check_models():
    """æ£€æŸ¥modelsç›®å½•ä¸­çš„æ¨¡å‹æ–‡ä»¶"""
    model_status = []
    
    # æœç´¢å¤šä¸ªè·¯å¾„ä¸­çš„æ¨¡å‹
    ltx_2b_model = find_ltx_model("ltx-video-2b")
    ltx_13b_model = find_ltx_model("ltxv-13b")
        
    # æ£€æŸ¥LTX 2Bæ¨¡å‹
    if ltx_2b_model:
        model_status.append(f"âœ… 2Bæ¨¡å‹: {os.path.basename(ltx_2b_model)}")
    else:
        model_status.append("âŒ æœªæ‰¾åˆ°2Bæ¨¡å‹")
    
    # æ£€æŸ¥LTX 13Bæ¨¡å‹
    if ltx_13b_model:
        model_status.append(f"âœ… 13Bæ¨¡å‹: {os.path.basename(ltx_13b_model)}")
    else:
        model_status.append("âŒ æœªæ‰¾åˆ°13Bæ¨¡å‹")
        
    return model_status

def run_preprocessing(dataset, resolution, id_token, decode_videos, status):
    """è¿è¡Œæ•°æ®é¢„å¤„ç†
    
    Args:
        dataset: æ•°æ®é›†åç§°æˆ–è·¯å¾„
        resolution: åˆ†è¾¨ç‡
        id_token: IDæ ‡è®°
        decode_videos: æ˜¯å¦è§£ç è§†é¢‘
        status: çŠ¶æ€ç»„ä»¶
    """
    initial_status = f"""====== æ•°æ®é¢„å¤„ç† ======
æ•°æ®é›†: {dataset}
åˆ†è¾¨ç‡: {resolution}
IDæ ‡è®°: {id_token if id_token else 'æ— '}
è§£ç è§†é¢‘: {'æ˜¯' if decode_videos else 'å¦'}
========================
"""
    
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
    dataset_path = check_dataset_location(dataset)
    if not dataset_path:
        error_msg = f"é”™è¯¯: æœªæ‰¾åˆ°æ•°æ®é›† '{dataset}'"
        logger.error(error_msg)
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        return initial_status + "\n" + error_msg
    
    # å‡†å¤‡å‘½ä»¤
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "preprocess_dataset.py"),
        dataset_path,
        "--resolution-buckets", resolution
    ]
    
    if id_token:
        cmd.extend(["--id-token", id_token])
    
    if decode_videos:
        cmd.append("--decode-videos")
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½é¢„å¤„ç†å‚æ•°
    config_path = os.path.join(CONFIG_DIR, "default_config.yaml")
    if os.path.exists(config_path):
        config = load_config(config_path)
        if config and 'preprocessing' in config:
            preproc_config = config['preprocessing']
            
            # æ˜¯å¦è·³è¿‡å·²å¤„ç†çš„åœºæ™¯
            if preproc_config.get('skip_existing_scenes', True):
                cmd.append("--skip-existing")
    
    # æ›´æ–°çŠ¶æ€
    update_msg = initial_status + f"\næ•°æ®é›†è·¯å¾„: {dataset_path}\n\nå‡†å¤‡è¿è¡Œé¢„å¤„ç†å‘½ä»¤...\n"
    if hasattr(status, 'update'):
        status.update(value=update_msg)
    
    # è¿è¡Œå‘½ä»¤
    logger.info(f"è¿è¡Œé¢„å¤„ç†å‘½ä»¤: {' '.join(cmd)}")
    try:
        returncode, output = run_command(cmd, status=status)
        if returncode == 0:
            success_msg = "\n\nâœ… é¢„å¤„ç†æˆåŠŸå®Œæˆ!"
            if hasattr(status, 'update'):
                status.update(value=output + success_msg)
            return output + success_msg
        else:
            error_msg = "\n\nâŒ é¢„å¤„ç†å¤±è´¥!"
            if hasattr(status, 'update'):
                status.update(value=output + error_msg)
            return output + error_msg
    except Exception as e:
        error_msg = f"\n\nâŒ é¢„å¤„ç†å‡ºé”™: {str(e)}"
        if hasattr(status, 'update'):
            status.update(value=update_msg + error_msg)
        return update_msg + error_msg

def convert_to_comfyui(input_path, output_path, status):
    """è½¬æ¢ä¸ºComfyUIæ ¼å¼
    
    Args:
        input_path: è¾“å…¥æ¨¡å‹è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
        status: çŠ¶æ€ç»„ä»¶
    """
    initial_status = f"""====== è½¬æ¢ä¸ºComfyUIæ ¼å¼ ======
è¾“å…¥è·¯å¾„: {input_path}
è¾“å‡ºè·¯å¾„: {output_path if output_path else 'è‡ªåŠ¨ç”Ÿæˆ'}
========================
"""
    
    if hasattr(status, 'update'):
        status.update(value=initial_status)
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        error_msg = f"é”™è¯¯: è¾“å…¥è·¯å¾„ä¸å­˜åœ¨ '{input_path}'"
        logger.error(error_msg)
        if hasattr(status, 'update'):
            status.update(value=initial_status + "\n" + error_msg)
        return initial_status + "\n" + error_msg
    
    # å‡†å¤‡å‘½ä»¤
    cmd = [
        sys.executable,
        os.path.join(SCRIPTS_DIR, "convert_checkpoint.py"),
        input_path,
        "--to-comfy"
    ]
    
    if output_path:
        cmd.extend(["--output_path", output_path])
    
    # æ›´æ–°çŠ¶æ€
    update_msg = initial_status + "\nå‡†å¤‡è½¬æ¢...\n"
    if hasattr(status, 'update'):
        status.update(value=update_msg)
    
    # è¿è¡Œå‘½ä»¤
    try:
        returncode, output = run_command(cmd, status=status)
        if returncode == 0:
            success_msg = "\n\nâœ… è½¬æ¢æˆåŠŸå®Œæˆ!"
            if hasattr(status, 'update'):
                status.update(value=output + success_msg)
            return output + success_msg
        else:
            error_msg = "\n\nâŒ è½¬æ¢å¤±è´¥!"
            if hasattr(status, 'update'):
                status.update(value=output + error_msg)
            return output + error_msg
    except Exception as e:
        error_msg = f"\n\nâŒ è½¬æ¢å‡ºé”™: {str(e)}"
        if hasattr(status, 'update'):
            status.update(value=update_msg + error_msg)
        return update_msg + error_msg

def main():
    """åˆ›å»ºGradio UIç•Œé¢"""
    with gr.Blocks(title="LTX-Video-Trainer ç¦»çº¿è®­ç»ƒå·¥å…·") as app:
        gr.Markdown("# ğŸš€ LTX-Video-Trainer ç¦»çº¿è®­ç»ƒå·¥å…·")
        gr.Markdown("### å®Œå…¨ç¦»çº¿æ¨¡å¼ - åŸºäºæœ¬åœ°æ¨¡å‹æ–‡ä»¶ç”ŸæˆLoRAæƒé‡")
        
        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        gr.Markdown("## æ¨¡å‹çŠ¶æ€")
        model_status = check_models()
        gr.Markdown("\n".join(model_status))
        
        with gr.Tabs():
            # ç¦»çº¿è®­ç»ƒæ¨¡å¼æ ‡ç­¾é¡µ
            with gr.TabItem("æœ¬åœ°ç¦»çº¿è®­ç»ƒ"):
                gr.Markdown("### ğŸ”¥ å®Œå…¨ç¦»çº¿æ¨¡å¼ - ä¸éœ€è¦ä¸‹è½½ä»»ä½•èµ„æº")
                gr.Markdown("è¯¥æ¨¡å¼ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶ç›´æ¥ç”ŸæˆLoRAæƒé‡ï¼Œç®€åŒ–è®­ç»ƒæµç¨‹å¹¶é¿å…ä»»ä½•ç½‘ç»œè¯·æ±‚")
                
                with gr.Row():
                    with gr.Column():
                        offline_basename = gr.Textbox(
                            label="é¡¹ç›®åç§°", 
                            placeholder="è¾“å…¥é¡¹ç›®åç§°ï¼Œå¦‚APTï¼Œæ•°æ®é›†åº”æ”¾åœ¨train_date/APTç›®å½•ä¸­"
                        )
                        gr.Markdown("æ”¯æŒçš„æ•°æ®é›†ä½ç½®ï¼š**train_date/{é¡¹ç›®å}** æˆ– **{é¡¹ç›®å}_raw**")
                        offline_model_size = gr.Radio(
                            label="æ¨¡å‹å¤§å°", 
                            choices=["2B", "13B"], 
                            value="2B",
                            info="2Bæ¨¡å‹éœ€è¦è¾ƒå°‘çš„æ˜¾å­˜ï¼Œ13Bæ¨¡å‹éœ€è¦æ›´å¤šæ˜¾å­˜ä½†è´¨é‡æ›´é«˜"
                        )
                        offline_resolution = gr.Dropdown(
                            label="åˆ†è¾¨ç‡", 
                            choices=RESOLUTIONS + ["576x1024x41"],
                            value="768x768x25",
                            info="æ ¼å¼ä¸ºå®½xé«˜xå¸§æ•°ï¼Œå¸§æ•°è¾ƒå°‘è®­ç»ƒæ›´å¿«"
                        )
                        offline_rank = gr.Slider(
                            label="LoRAç§© (Rank)", 
                            minimum=1, 
                            maximum=128, 
                            value=32,
                            info="å€¼è¶Šå¤§ï¼Œé€‚åº”æ€§è¶Šå¼ºä½†éœ€è¦æ›´å¤šæ˜¾å­˜"
                        )
                        offline_steps = gr.Slider(
                            label="è®­ç»ƒæ­¥æ•°", 
                            minimum=5, 
                            maximum=200, 
                            value=50,
                            info="æ­¥æ•°è¶Šå¤šï¼Œè®­ç»ƒæ—¶é—´è¶Šé•¿ï¼Œä½†æ•ˆæœå¯èƒ½æ›´å¥½"
                        )
                        offline_button = gr.Button(
                            "å¼€å§‹æœ¬åœ°ç¦»çº¿è®­ç»ƒ", 
                            variant="primary"
                        )
                    
                    with gr.Column():
                        offline_status = gr.Textbox(
                            label="è®­ç»ƒæ—¥å¿—", 
                            lines=25,
                            max_lines=30,
                            autoscroll=True
                        )
                
                offline_button.click(
                    fn=run_offline_training,
                    inputs=[
                        offline_basename, 
                        offline_model_size, 
                        offline_resolution, 
                        offline_rank, 
                        offline_steps, 
                        offline_status
                    ],
                    outputs=offline_status
                )
        
        # é¡µè„šä¿¡æ¯
        gr.Markdown("---")
        gr.Markdown("### ğŸ“ ä½¿ç”¨è¯´æ˜")
        gr.Markdown("""
        1. ç¡®ä¿æ‚¨çš„æ•°æ®é›†å·²æ”¾åœ¨æ­£ç¡®ä½ç½®: `train_date/{é¡¹ç›®å}` æˆ– `{é¡¹ç›®å}_raw`
        2. é€‰æ‹©åˆé€‚çš„æ¨¡å‹å¤§å°ã€åˆ†è¾¨ç‡å’Œè®­ç»ƒå‚æ•°
        3. ç‚¹å‡»"å¼€å§‹æœ¬åœ°ç¦»çº¿è®­ç»ƒ"æŒ‰é’®
        4. è®­ç»ƒæ—¥å¿—ä¼šå®æ—¶æ˜¾ç¤ºåœ¨å³ä¾§æ–‡æœ¬æ¡†å’Œç»ˆç«¯ä¸­
        5. è®­ç»ƒå®Œæˆåï¼ŒLoRAæ–‡ä»¶å°†ä¿å­˜åœ¨ `outputs/{é¡¹ç›®å}_offline_training/lora_weights` ç›®å½•
        """)
        
    # å¯åŠ¨UI
    app.launch(server_name="127.0.0.1", server_port=7860)

if __name__ == "__main__":
    main()
